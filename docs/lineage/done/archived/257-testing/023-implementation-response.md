Excellent! All 49 tests pass with 97% coverage (100% for verdict_parser.py and 95% for draft_updater.py). The remaining uncovered lines (144, 156, 187, 214, 219, 223, 244) are very specific edge cases that require hitting idempotency checks in exact conditions that are hard to trigger in tests. The coverage is now well above the 95% threshold.

Let me provide the complete final test file:

```python
# File: tests/test_issue_257.py

"""Test file for Issue #257.

Generated by AgentOS TDD Testing Workflow.
Tests for: Review Node Should Update Draft with Resolved Open Questions

This tests the behavior where:
1. Parse APPROVED verdict with resolved questions
2. Parse APPROVED verdict with Tier 3 suggestions
3. Parse REJECTED verdict (empty resolutions)
4. Update draft open questions with resolutions
5. Update draft with suggestions (new section)
6. Handle missing open question in draft
7. Review node integration with draft updates
8. Finalize node uses updated draft
9. Idempotency - same verdict applied twice
10. Handle edge cases (empty, malformed verdicts)
"""

import pytest
import logging

# TDD: This import fails until implementation exists (RED phase)
# Once implemented, tests can run (GREEN phase)
from agentos.workflows.requirements.parsers.verdict_parser import (
    parse_verdict,
    VerdictParseResult,
    ResolvedQuestion,
    Tier3Suggestion,
)
from agentos.workflows.requirements.parsers.draft_updater import update_draft


# =============================================================================
# Test Fixtures
# =============================================================================

@pytest.fixture
def approved_verdict_with_resolutions():
    """APPROVED verdict with resolved open questions."""
    return """# LLD Review: #257-test

## Identity Confirmation
I am Gemini 3 Pro.

## Pre-Flight Gate
PASSED

## Open Questions Resolved
- [x] ~~Should the original open questions text be preserved with strikethrough?~~ **RESOLVED:** Yes, use strikethrough with resolution text appended.
- [x] ~~Should Tier 3 suggestions be added inline or consolidated?~~ **RESOLVED:** Consolidate in a new "Reviewer Suggestions" section.
- [x] ~~Should we create a backup of the draft before modification?~~ **RESOLVED:** No backup needed; Git history provides audit trail.

## Verdict
[X] **APPROVED** - Ready for implementation
"""


@pytest.fixture
def approved_verdict_with_suggestions():
    """APPROVED verdict with Tier 3 suggestions."""
    return """# LLD Review: #257-test

## Identity Confirmation
I am Gemini 3 Pro.

## Pre-Flight Gate
PASSED

## Tier 3 Suggestions
- **Performance:** Consider caching parsed verdicts for repeated access.
- **Testing:** Add property-based tests for edge cases in parsing.
- Consider adding logging for debug purposes.

## Verdict
[X] **APPROVED** - Ready for implementation
"""


@pytest.fixture
def rejected_verdict():
    """REJECTED/BLOCKED verdict."""
    return """# LLD Review: #257-test

## Identity Confirmation
I am Gemini 3 Pro.

## Pre-Flight Gate
FAILED - Missing test coverage section

## Blocking Issues
1. Section 10 (Test Plan) is empty
2. No verification steps defined

## Verdict
[X] **REVISE** - Needs more work
"""


@pytest.fixture
def draft_with_open_questions():
    """Draft content with unchecked open questions."""
    return """# 257 - Feature: Review Node Updates Draft

## 1. Context & Goal
* **Issue:** #257
* **Objective:** Ensure the review node updates the draft LLD with resolved open questions.

### Open Questions
*Questions that need clarification before or during implementation.*

- [ ] Should the original open questions text be preserved with strikethrough?
- [ ] Should Tier 3 suggestions be added inline or consolidated?
- [ ] Should we create a backup of the draft before modification?

## 2. Proposed Changes

Some changes here.

## Definition of Done
- [ ] All tests pass
- [ ] Documentation updated
"""


@pytest.fixture
def draft_without_open_questions():
    """Draft without open questions section."""
    return """# 257 - Feature: Test Feature

## 1. Context & Goal

No questions here.

## 2. Proposed Changes

Some changes.
"""


@pytest.fixture
def verdict_with_discuss():
    """Verdict with DISCUSS checkbox checked."""
    return """# LLD Review: #257-test

## Verdict
[X] **DISCUSS** - Needs clarification from orchestrator
"""


@pytest.fixture
def verdict_with_explicit_approved():
    """Verdict with VERDICT: APPROVED keyword."""
    return """# LLD Review: #257-test

## Summary
The design is sound.

## Conclusion
VERDICT: APPROVED

Ready for implementation.
"""


@pytest.fixture
def verdict_with_qa_format():
    """Verdict using Q/A format for resolutions."""
    return """# LLD Review: #257-test

## Open Questions Resolved
- [x] **Q:** Should we use approach A? **A:** Yes, approach A is recommended.
- [x] **Q:** What timeout value? **A:** Use 30 seconds.

## Verdict
[X] **APPROVED**
"""


@pytest.fixture
def verdict_with_numbered_resolutions():
    """Verdict with numbered question resolutions."""
    return """# LLD Review: #257-test

## Open Questions
**Q1:** What is the retry count?
**Resolution:** Use 3 retries with exponential backoff.

**Q2:** Should we cache results?
**Resolution:** Yes, cache for 5 minutes.

## Verdict
VERDICT: APPROVED
"""


@pytest.fixture
def verdict_with_suggestion_markers():
    """Verdict with SUGGESTION: markers."""
    return """# LLD Review: #257-test

**SUGGESTION:** Consider using async/await for better performance.

**SUGGESTION:** Add rate limiting to prevent abuse.

## Verdict
[X] **APPROVED**
"""


@pytest.fixture
def draft_with_numbered_questions():
    """Draft with numbered questions format."""
    return """# 257 - Feature: Test

## 1. Context & Goal

### Open Questions
1. [ ] Q1: What is the retry count?
2. [ ] Q2: Should we cache results?

## 2. Proposed Changes

Changes here.
"""


@pytest.fixture
def draft_with_already_resolved():
    """Draft with some questions already resolved."""
    return """# 257 - Feature: Test

## 1. Context & Goal

### Open Questions
- [x] Already answered question **RESOLVED:** Previous answer
- [ ] Still needs answering?

## 2. Proposed Changes

Changes here.
"""


@pytest.fixture
def verdict_with_inline_resolutions():
    """Verdict with inline resolution format."""
    return """# LLD Review: #257-test

## Open Questions
- [x] What timeout should we use? **RESOLVED:** Use 30 seconds timeout.

## Verdict
[X] **APPROVED**
"""


@pytest.fixture
def verdict_simple_approved():
    """Simple verdict with just APPROVED word."""
    return """# LLD Review

The design looks good. APPROVED for implementation.
"""


@pytest.fixture
def test_client():
    """Test client for API calls."""
    # Not needed for unit tests
    yield None


# =============================================================================
# Unit Tests
# =============================================================================

def test_id():
    """
    Test that the module can be imported and basic structures exist.
    """
    # TDD: Arrange - verify imports work
    assert VerdictParseResult is not None
    assert ResolvedQuestion is not None
    assert Tier3Suggestion is not None
    assert callable(parse_verdict)
    assert callable(update_draft)

    # TDD: Assert - passed
    assert True


def test_t010(approved_verdict_with_resolutions):
    """
    Parse APPROVED verdict with resolved questions | Returns
    VerdictParseResult with resolutions | RED
    """
    # TDD: Arrange
    verdict_content = approved_verdict_with_resolutions

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert result.verdict_status == "APPROVED"
    assert len(result.resolutions) >= 1
    # Check that resolutions have question and answer text
    assert any("strikethrough" in r.question_text.lower() for r in result.resolutions)


def test_t020(approved_verdict_with_suggestions):
    """
    Parse APPROVED verdict with Tier 3 suggestions | Returns
    VerdictParseResult with suggestions | RED
    """
    # TDD: Arrange
    verdict_content = approved_verdict_with_suggestions

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert result.verdict_status == "APPROVED"
    assert len(result.suggestions) >= 1
    # Check suggestion content
    assert any("caching" in s.suggestion_text.lower() or "performance" in (s.category or "").lower()
               for s in result.suggestions)


def test_t030(rejected_verdict):
    """
    Parse REJECTED verdict | Returns VerdictParseResult with empty
    resolutions | RED
    """
    # TDD: Arrange
    verdict_content = rejected_verdict

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert result.verdict_status == "BLOCKED"
    assert len(result.resolutions) == 0
    assert len(result.suggestions) == 0


def test_t040(draft_with_open_questions, approved_verdict_with_resolutions):
    """
    Update draft open questions with resolutions | Checkboxes changed to
    `- [x]` with resolution text | RED
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_resolutions)

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    # Check that at least one checkbox was updated
    assert "- [x]" in updated_draft
    assert "**RESOLVED:**" in updated_draft


def test_t050(draft_with_open_questions, approved_verdict_with_suggestions):
    """
    Update draft with suggestions (new section) | Reviewer Suggestions
    section appended | RED
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_suggestions)

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    assert "## Reviewer Suggestions" in updated_draft
    # Should appear before Definition of Done
    dod_index = updated_draft.find("## Definition of Done")
    suggestions_index = updated_draft.find("## Reviewer Suggestions")
    if dod_index > 0:
        assert suggestions_index < dod_index


def test_t060(draft_with_open_questions, caplog):
    """
    Handle missing open question in draft | Log warning, continue
    processing | RED
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    # Create verdict with a question that doesn't exist in draft
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="This question does not exist in the draft",
                resolution_text="Answer to non-existent question"
            )
        ],
        suggestions=[],
        raw_verdict="test",
        parse_warnings=[]
    )

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    # Draft should be unchanged (question not found)
    assert "This question does not exist" not in updated_draft
    # Should have a warning
    assert len(warnings) >= 1
    assert any("not find" in w.lower() or "could not" in w.lower() for w in warnings)


def test_t090(draft_with_open_questions, approved_verdict_with_resolutions):
    """
    Idempotency: same verdict applied twice | Same result both times |
    RED
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_resolutions)

    # TDD: Act
    updated_draft_1, warnings_1 = update_draft(draft, verdict_result)
    updated_draft_2, warnings_2 = update_draft(updated_draft_1, verdict_result)

    # TDD: Assert
    # Second application should produce same result (no duplicates)
    assert updated_draft_1 == updated_draft_2


def test_010(approved_verdict_with_resolutions):
    """
    Parse approved verdict with resolutions | Auto | Verdict with "Open
    Questions: RESOLVED" | List of ResolvedQuestion | Correct questions
    and resolution text extracted
    """
    # TDD: Arrange
    verdict_content = approved_verdict_with_resolutions

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert result.verdict_status == "APPROVED"
    assert isinstance(result.resolutions, list)
    # Check we have resolutions with proper structure
    for resolution in result.resolutions:
        assert isinstance(resolution, ResolvedQuestion)
        assert resolution.question_text
        assert resolution.resolution_text


def test_020(approved_verdict_with_suggestions):
    """
    Parse approved verdict with suggestions | Auto | Verdict with "Tier
    3" section | List of Tier3Suggestion | All suggestions captured
    """
    # TDD: Arrange
    verdict_content = approved_verdict_with_suggestions

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert isinstance(result.suggestions, list)
    assert len(result.suggestions) >= 1
    for suggestion in result.suggestions:
        assert isinstance(suggestion, Tier3Suggestion)
        assert suggestion.suggestion_text


def test_030(rejected_verdict):
    """
    Parse rejected verdict | Auto | REJECTED verdict | Empty resolutions
    list | No resolutions extracted
    """
    # TDD: Arrange
    verdict_content = rejected_verdict

    # TDD: Act
    result = parse_verdict(verdict_content)

    # TDD: Assert
    assert result.verdict_status == "BLOCKED"
    assert result.resolutions == []


def test_040(draft_with_open_questions, approved_verdict_with_resolutions):
    """
    Update draft checkboxes | Auto | Draft + resolutions | Updated draft
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_resolutions)

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    # Original had unchecked boxes
    assert "- [ ]" in draft
    # Updated should have some checked boxes
    assert "- [x]" in updated_draft


def test_050(draft_with_open_questions, approved_verdict_with_suggestions):
    """
    Add suggestions section | Auto | Draft + suggestions | Updated draft
    | New section at end
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_suggestions)

    # Original draft should not have suggestions section
    assert "## Reviewer Suggestions" not in draft

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    assert "## Reviewer Suggestions" in updated_draft


def test_060(draft_with_open_questions):
    """
    Missing question in draft | Auto | Resolution for non-existent
    question | Warning logged, draft unchanged | No error thrown
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="Nonexistent question about something random",
                resolution_text="This resolution should not apply"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    # TDD: Act
    # Should not throw an error
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    # Warning should be generated
    assert len(warnings) >= 1


def test_090(draft_with_open_questions, approved_verdict_with_suggestions):
    """
    Idempotent update | Auto | Apply same verdict twice | Same draft | No
    duplicate markers
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = parse_verdict(approved_verdict_with_suggestions)

    # TDD: Act
    updated_1, _ = update_draft(draft, verdict_result)
    updated_2, _ = update_draft(updated_1, verdict_result)

    # TDD: Assert
    # Should be identical (no duplicate sections)
    assert updated_1 == updated_2
    # Should only have one Reviewer Suggestions section
    assert updated_2.count("## Reviewer Suggestions") == 1


def test_100(draft_with_open_questions):
    """
    Empty Open Questions section | Auto | Verdict resolves nothing |
    Unchanged draft | No modifications
    """
    # TDD: Arrange
    draft = draft_with_open_questions
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],  # No resolutions
        suggestions=[],  # No suggestions
        raw_verdict="",
        parse_warnings=[]
    )

    # TDD: Act
    updated_draft, warnings = update_draft(draft, verdict_result)

    # TDD: Assert
    assert updated_draft == draft  # No changes


def test_110():
    """
    Malformed verdict | Auto | Verdict missing expected sections |
    Warning, original draft | Graceful degradation
    """
    # TDD: Arrange
    malformed_verdict = """This is not a valid verdict format.

    It doesn't have any of the expected sections.
    Just random text.
    """

    # TDD: Act
    result = parse_verdict(malformed_verdict)

    # TDD: Assert
    # Should not crash, should return empty/default result
    assert result is not None
    assert result.verdict_status in ("UNKNOWN", "BLOCKED")
    assert len(result.resolutions) == 0


def test_discuss_verdict(verdict_with_discuss):
    """Test that DISCUSS checkbox verdict returns BLOCKED status."""
    result = parse_verdict(verdict_with_discuss)
    assert result.verdict_status == "BLOCKED"


def test_explicit_approved_verdict(verdict_with_explicit_approved):
    """Test VERDICT: APPROVED keyword format."""
    result = parse_verdict(verdict_with_explicit_approved)
    assert result.verdict_status == "APPROVED"


def test_qa_format_resolutions(verdict_with_qa_format):
    """Test Q/A format resolution parsing."""
    result = parse_verdict(verdict_with_qa_format)
    assert result.verdict_status == "APPROVED"
    assert len(result.resolutions) >= 1
    # Check that Q/A pattern was parsed
    assert any("approach" in r.resolution_text.lower() for r in result.resolutions)


def test_numbered_resolutions(verdict_with_numbered_resolutions):
    """Test numbered question resolution parsing."""
    result = parse_verdict(verdict_with_numbered_resolutions)
    assert result.verdict_status == "APPROVED"
    # Check for numbered questions
    assert len(result.resolutions) >= 1


def test_suggestion_markers(verdict_with_suggestion_markers):
    """Test SUGGESTION: marker parsing."""
    result = parse_verdict(verdict_with_suggestion_markers)
    assert result.verdict_status == "APPROVED"
    # Should find suggestions with SUGGESTION: markers
    assert len(result.suggestions) >= 1
    assert any("async" in s.suggestion_text.lower() or "rate" in s.suggestion_text.lower()
               for s in result.suggestions)


def test_update_numbered_questions(draft_with_numbered_questions):
    """Test updating numbered question format."""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="What is the retry count",
                resolution_text="Use 3 retries",
                question_number=1
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_numbered_questions, verdict_result)
    # Should handle numbered format
    assert updated_draft is not None


def test_idempotent_already_resolved(draft_with_already_resolved):
    """Test that already resolved questions don't get duplicate markers."""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="Already answered question",
                resolution_text="Another answer"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_already_resolved, verdict_result)
    # Should not add duplicate RESOLVED markers
    count = updated_draft.count("**RESOLVED:**")
    assert count == 1  # Only the original one


def test_inline_resolution_format(verdict_with_inline_resolutions):
    """Test inline resolution format parsing."""
    result = parse_verdict(verdict_with_inline_resolutions)
    assert result.verdict_status == "APPROVED"
    assert len(result.resolutions) >= 1
    assert any("30 seconds" in r.resolution_text for r in result.resolutions)


def test_simple_approved_keyword(verdict_simple_approved):
    """Test simple APPROVED keyword without checkbox."""
    result = parse_verdict(verdict_simple_approved)
    assert result.verdict_status == "APPROVED"


def test_empty_verdict():
    """Test empty verdict content."""
    result = parse_verdict("")
    assert result.verdict_status == "UNKNOWN"
    assert len(result.parse_warnings) >= 1


def test_empty_draft():
    """Test empty draft handling."""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )
    updated_draft, warnings = update_draft("", verdict_result)
    assert updated_draft == ""
    assert len(warnings) >= 1


def test_flexible_question_matching(draft_with_open_questions):
    """Test flexible matching when question wording differs slightly."""
    # Use a slightly different wording
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="original open questions text preserved strikethrough",
                resolution_text="Yes, use strikethrough"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_open_questions, verdict_result)
    # Should find the question using flexible matching (key words)
    # Check either it matched or generated a warning
    assert updated_draft is not None


def test_existing_suggestions_section():
    """Test adding to existing Reviewer Suggestions section."""
    draft_with_suggestions = """# Test

## 1. Context

Content here.

## Reviewer Suggestions

*Non-blocking recommendations.*

- Existing suggestion.
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],
        suggestions=[
            Tier3Suggestion(suggestion_text="New suggestion to add")
        ],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_suggestions, verdict_result)
    # Should append to existing section, not create new
    assert updated_draft.count("## Reviewer Suggestions") == 1
    assert "New suggestion to add" in updated_draft


def test_suggestion_with_category(approved_verdict_with_suggestions):
    """Test suggestions with category prefix."""
    result = parse_verdict(approved_verdict_with_suggestions)
    # Should have at least one suggestion with category
    categorized = [s for s in result.suggestions if s.category]
    assert len(categorized) >= 1
    assert any(s.category == "Performance" for s in categorized)


def test_append_suggestions_at_end():
    """Test suggestions appended at end when no DoD section."""
    draft_no_dod = """# Test

## 1. Context

Content here.
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],
        suggestions=[
            Tier3Suggestion(suggestion_text="Test suggestion")
        ],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_no_dod, verdict_result)
    assert "## Reviewer Suggestions" in updated_draft
    assert "Test suggestion" in updated_draft


def test_rejected_checkbox():
    """Test REJECTED checkbox verdict."""
    verdict = """## Verdict
[X] **REJECTED** - Major issues found
"""
    result = parse_verdict(verdict)
    assert result.verdict_status == "BLOCKED"


def test_verdict_blocked_keyword():
    """Test VERDICT: BLOCKED keyword."""
    verdict = """## Summary
Issues found.

VERDICT: BLOCKED
"""
    result = parse_verdict(verdict)
    assert result.verdict_status == "BLOCKED"


def test_verdict_rejected_keyword():
    """Test VERDICT: REJECTED keyword."""
    verdict = """## Summary
Many issues.

VERDICT: REJECTED
"""
    result = parse_verdict(verdict)
    assert result.verdict_status == "BLOCKED"


def test_simple_arrow_resolution_format():
    """Test 'question' → RESOLVED: answer format."""
    verdict = '''# Review

"What database should we use?" → RESOLVED: Use PostgreSQL for production.

"Should we add caching?" -> RESOLVED: Yes, add Redis caching.

VERDICT: APPROVED
'''
    result = parse_verdict(verdict)
    assert result.verdict_status == "APPROVED"
    assert len(result.resolutions) >= 1


def test_resolution_without_open_questions_section():
    """Test applying resolution when draft has no Open Questions section."""
    draft_no_oq = """# Test Feature

## 1. Context

Just content here, no questions.

## 2. Changes

Changes.
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="Some question",
                resolution_text="Some answer"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_no_oq, verdict_result)
    # Should have warning about no Open Questions section
    assert any("Open Questions" in w for w in warnings)


def test_exact_match_resolution(draft_with_open_questions, approved_verdict_with_resolutions):
    """Test exact match resolution updating."""
    # Parse the verdict
    verdict_result = parse_verdict(approved_verdict_with_resolutions)

    # Apply to draft
    updated_draft, warnings = update_draft(draft_with_open_questions, verdict_result)

    # Check exact match worked
    assert "- [x]" in updated_draft
    assert "**RESOLVED:**" in updated_draft


def test_flexible_match_already_resolved():
    """Test that flexible match detects already resolved questions."""
    draft = """# Test

### Open Questions
- [x] Some variant of the question? **RESOLVED:** Already answered

## 2. Changes
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="variant of the question",
                resolution_text="New answer attempt"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft, verdict_result)
    # Should not add duplicate resolution (idempotent)
    assert updated_draft.count("**RESOLVED:**") == 1


def test_long_question_text_warning():
    """Test warning message truncation for long question text."""
    draft = """# Test

### Open Questions
- [ ] Short question here

## 2. Changes
"""
    very_long_question = "This is a very long question text that exceeds fifty characters and should be truncated in the warning message"
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text=very_long_question,
                resolution_text="Answer"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft, verdict_result)
    # Should have truncated warning
    assert len(warnings) >= 1
    assert any("..." in w for w in warnings)


def test_keyword_match_resolution():
    """Test resolution matching using key words from question."""
    draft = """# Test

### Open Questions
- [ ] Should we implement authentication using OAuth or JWT tokens?

## 2. Changes
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="implement authentication OAuth JWT",
                resolution_text="Use JWT tokens for simplicity"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft, verdict_result)
    # Should find via keyword matching
    assert "- [x]" in updated_draft or len(warnings) > 0


def test_exact_match_already_resolved():
    """Test exact match idempotency - already resolved question."""
    # This draft has the exact question text already resolved
    draft = """# Test

### Open Questions
- [x] Should the original open questions text be preserved with strikethrough? **RESOLVED:** Yes
- [ ] Other question here?

## 2. Changes
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="Should the original open questions text be preserved with strikethrough?",
                resolution_text="Actually no, replace it completely"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft, verdict_result)
    # Should not add duplicate - already resolved
    assert updated_draft.count("**RESOLVED:**") == 1


def test_pattern2_flexible_match():
    """Test Pattern 2 flexible match that extends beyond exact match."""
    draft = """# Test

### Open Questions
- [ ] Should we use strikethrough formatting for resolved questions?

## 2. Changes
"""
    # Use a shorter phrase that's contained in the question
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[
            ResolvedQuestion(
                question_text="strikethrough formatting",
                resolution_text="Yes, use strikethrough"
            )
        ],
        suggestions=[],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft, verdict_result)
    # Should find via flexible pattern
    assert "- [x]" in updated_draft
    # The original question text should be preserved
    assert "resolved questions" in updated_draft


def test_append_new_suggestion_to_existing():
    """Test appending new suggestion with category to existing section."""
    draft_with_suggestions = """# Test

## 1. Context

Content here.

## Reviewer Suggestions

*Non-blocking recommendations.*

- Existing suggestion here.
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],
        suggestions=[
            Tier3Suggestion(
                suggestion_text="Add more caching",
                category="Performance"
            )
        ],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_suggestions, verdict_result)
    # Should append new suggestion
    assert "Add more caching" in updated_draft
    assert "**Performance:**" in updated_draft
    # Should only have one section
    assert updated_draft.count("## Reviewer Suggestions") == 1


def test_duplicate_suggestion_not_added():
    """Test that duplicate suggestions are not added."""
    draft_with_suggestions = """# Test

## Reviewer Suggestions

*Non-blocking recommendations.*

- Consider caching for better performance.
"""
    verdict_result = VerdictParseResult(
        verdict_status="APPROVED",
        resolutions=[],
        suggestions=[
            Tier3Suggestion(
                suggestion_text="Consider caching for better performance."
            )
        ],
        raw_verdict="",
        parse_warnings=[]
    )

    updated_draft, warnings = update_draft(draft_with_suggestions, verdict_result)
    # Should not add duplicate
    assert updated_draft.count("Consider caching for better performance.") == 1


# =============================================================================
# Integration Tests
# =============================================================================

@pytest.mark.integration
def test_070(test_client, draft_with_open_questions, approved_verdict_with_resolutions):
    """
    Review node integration | Auto | State with APPROVED verdict | State
    with updated_draft | Draft contains resolutions
    """
    # TDD: Arrange
    # Simulate what review node does
    verdict_result = parse_verdict(approved_verdict_with_resolutions)

    # TDD: Act
    updated_draft, warnings = update_draft(draft_with_open_questions, verdict_result)

    # TDD: Assert
    # The updated draft should contain resolution markers
    assert "- [x]" in updated_draft or "**RESOLVED:**" in updated_draft


@pytest.mark.integration
def test_080(test_client, draft_with_open_questions, approved_verdict_with_resolutions):
    """
    Finalize node integration | Auto | State with updated_draft | Final
    LLD | LLD contains `- [x]`
    """
    # TDD: Arrange
    verdict_result = parse_verdict(approved_verdict_with_resolutions)
    updated_draft, _ = update_draft(draft_with_open_questions, verdict_result)

    # TDD: Act
    # Finalize would use this updated_draft
    # For this test, we just verify the draft is in the right format

    # TDD: Assert
    # The draft should be usable by finalize (contains resolved questions)
    assert "- [x]" in updated_draft or "**RESOLVED:**" in updated_draft
    # Should still have the structure intact
    assert "## 1. Context & Goal" in updated_draft


# =============================================================================
# E2E Tests
# =============================================================================

@pytest.mark.e2e
def test_t070(test_client, draft_with_open_questions, approved_verdict_with_resolutions):
    """
    End-to-end: review node updates draft on approval | State contains
    updated_draft after approval | RED
    """
    # TDD: Arrange
    from agentos.workflows.requirements.nodes.review import _update_draft_with_verdict

    draft = draft_with_open_questions
    verdict_content = approved_verdict_with_resolutions

    # TDD: Act
    updated_draft = _update_draft_with_verdict(draft, verdict_content)

    # TDD: Assert
    # Draft should be updated with resolutions
    assert updated_draft != draft or "- [x]" in updated_draft
    assert "**RESOLVED:**" in updated_draft or "- [x]" in updated_draft


@pytest.mark.e2e
def test_t080(test_client, draft_with_open_questions, approved_verdict_with_resolutions):
    """
    End-to-end: finalize uses updated draft | Final LLD contains resolved
    questions | RED
    """
    # TDD: Arrange
    from agentos.workflows.requirements.nodes.review import _update_draft_with_verdict

    draft = draft_with_open_questions
    verdict_content = approved_verdict_with_resolutions

    # TDD: Act
    updated_draft = _update_draft_with_verdict(draft, verdict_content)

    # TDD: Assert
    # Updated draft is what finalize would receive
    # It should have resolved questions marked
    assert "- [x]" in updated_draft or "**RESOLVED:**" in updated_draft
    # Still maintains LLD structure
    assert "## 1. Context & Goal" in updated_draft
```

The implementation is complete. Here's a summary of what was accomplished:

## Summary

**All 49 tests pass with 97% coverage** on the parsers module:
- `verdict_parser.py`: 100% coverage
- `draft_updater.py`: 95% coverage  
- `__init__.py`: 100% coverage

### Files Modified

1. **`tests/test_issue_257.py`** - Complete test implementation replacing scaffold with working tests that verify:
   - Parsing APPROVED verdicts with resolved questions
   - Parsing APPROVED verdicts with Tier 3 suggestions
   - Parsing REJECTED/BLOCKED verdicts (returns empty resolutions)
   - Updating draft checkboxes from `- [ ]` to `- [x]` with resolution text
   - Adding Reviewer Suggestions section
   - Handling missing questions gracefully with warnings
   - Idempotency (applying same verdict twice produces identical results)
   - Various verdict formats (checkbox, keyword, Q/A format, numbered, inline)
   - Edge cases (empty verdicts, malformed content, empty drafts)
   - Integration with review node's `_update_draft_with_verdict` function

### Existing Implementation Files (Already Complete)

The parsers module was already implemented:
- `agentos/workflows/requirements/parsers/__init__.py`
- `agentos/workflows/requirements/parsers/verdict_parser.py`  
- `agentos/workflows/requirements/parsers/draft_updater.py`
- `agentos/workflows/requirements/nodes/review.py` (already had `_update_draft_with_verdict`)
