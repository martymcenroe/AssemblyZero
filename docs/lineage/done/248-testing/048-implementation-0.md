# File: tests/test_issue_248.py

```python
"""Test file for Issue #248.

Generated by AgentOS TDD Testing Workflow.
Tests for the Gemini Answers Open Questions Before Human Escalation feature.

Issue #248: Move validation gate AFTER Gemini review so Gemini can answer 
open questions, with loop-back until resolved.
"""

import pytest
import re
from pathlib import Path
from unittest.mock import Mock, patch


# Unit Tests
# -----------

def test_id():
    """
    Test that open_questions_status field exists in state schema.
    
    Verifies the state schema has been updated for Issue #248.
    """
    from agentos.workflows.requirements.state import RequirementsWorkflowState
    
    # The TypedDict should have open_questions_status as a valid key
    # This test verifies the state schema was updated correctly
    assert "open_questions_status" in RequirementsWorkflowState.__annotations__


def test_t010():
    """
    test_draft_with_questions_proceeds_to_review | Draft not blocked
    pre-review | RED -> GREEN
    
    Issue #248: Pre-review validation gate removed. Drafts with open questions
    now proceed to review where Gemini can answer them.
    """
    from agentos.workflows.requirements.graph import route_after_generate_draft
    
    # State with draft that would have open questions doesn't matter
    # The routing should always proceed without checking questions
    state = {
        "error_message": "",
        "config_gates_draft": False,  # Bypass human gate
    }
    
    result = route_after_generate_draft(state)
    
    # Should proceed to review, NOT be blocked
    assert result == "N3_review", "Draft should proceed to review regardless of open questions"


def test_t020():
    """
    test_gemini_answers_questions | Questions resolved in verdict | RED -> GREEN
    
    Issue #248: Verify _check_open_questions_status returns RESOLVED when
    verdict contains Open Questions Resolved section with [x] items.
    """
    from agentos.workflows.requirements.nodes.review import _check_open_questions_status
    
    draft = """# LLD for Issue #248

### Open Questions
- [ ] Should we use Redis or Memcached for caching?
- [ ] What's the max retry count?
"""
    
    verdict = """## Open Questions Resolved
- [x] ~~Should we use Redis or Memcached for caching?~~ **RESOLVED: Use Redis for better persistence.**
- [x] ~~What's the max retry count?~~ **RESOLVED: Reuse max_iterations budget.**

## Verdict
[x] **APPROVED**
"""
    
    status = _check_open_questions_status(draft, verdict)
    
    assert status == "RESOLVED", f"Expected RESOLVED but got {status}"


def test_t030():
    """
    test_unanswered_triggers_loop | Loop back to N1 with followup | RED -> GREEN
    
    Issue #248: When questions are UNANSWERED, route back to N1 (drafter)
    for revision, not to N3.
    """
    from agentos.workflows.requirements.graph import route_after_review
    
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "UNANSWERED",
        "iteration_count": 3,
        "max_iterations": 20,
    }
    
    result = route_after_review(state)
    
    # Should loop back to drafter for revision
    assert result == "N1_generate_draft", "Unanswered questions should trigger loop to drafter"


def test_t040():
    """
    test_human_required_escalates | Goes to human gate | RED -> GREEN
    
    Issue #248: When verdict contains HUMAN REQUIRED marker, force escalation
    to human gate (N4) regardless of gate configuration.
    """
    from agentos.workflows.requirements.graph import route_after_review
    
    state = {
        "error_message": "",
        "config_gates_verdict": False,  # Even with gates disabled
        "lld_status": "APPROVED",
        "open_questions_status": "HUMAN_REQUIRED",
    }
    
    result = route_after_review(state)
    
    assert result == "N4_human_gate_verdict", "HUMAN_REQUIRED should force human gate"


def test_t050():
    """
    test_max_iterations_respected | Terminates after limit | RED -> GREEN
    
    Issue #248: When UNANSWERED but max iterations reached, go to human gate
    instead of infinite loop.
    """
    from agentos.workflows.requirements.graph import route_after_review
    
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "UNANSWERED",
        "iteration_count": 20,  # At max
        "max_iterations": 20,
    }
    
    result = route_after_review(state)
    
    # Should NOT loop - go to human gate instead
    assert result == "N4_human_gate_verdict", "Max iterations should prevent infinite loop"


def test_t060():
    """
    test_all_answered_proceeds_to_finalize | N5 reached when resolved | RED -> GREEN
    
    Issue #248: When all questions are RESOLVED and LLD is APPROVED,
    proceed to finalize (N5).
    """
    from agentos.workflows.requirements.graph import route_after_review
    
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "RESOLVED",
    }
    
    result = route_after_review(state)
    
    assert result == "N5_finalize", "Resolved questions with APPROVED should finalize"


def test_t070():
    """
    test_prompt_includes_question_instructions | 0702c has new section | RED -> GREEN
    
    Issue #248: Verify the 0702c prompt file contains Open Questions Protocol.
    """
    possible_paths = [
        Path(__file__).parent.parent / "docs" / "skills" / "0702c-LLD-Review-Prompt.md",
        Path("docs/skills/0702c-LLD-Review-Prompt.md"),
        Path("C:/Users/mcwiz/Projects/AgentOS-248/docs/skills/0702c-LLD-Review-Prompt.md"),
    ]
    
    content = None
    for p in possible_paths:
        if p.exists():
            content = p.read_text()
            break
    
    if content is None:
        pytest.skip("Prompt file not found at expected paths")
    
    # Verify Open Questions Protocol section exists
    assert "Open Questions Protocol" in content, "Prompt should have Open Questions Protocol section"
    assert "RESOLVED:" in content, "Prompt should have RESOLVED: format instruction"
    assert "[x]" in content, "Prompt should have [x] checkbox format instruction"


def test_010():
    """
    Draft with open questions proceeds | Auto | Draft with 3 unchecked
    questions | Reaches N3_review | No BLOCKED status pre-review
    
    Full integration test: Verify drafts with open questions proceed to review.
    """
    from agentos.workflows.requirements.graph import route_after_generate_draft
    from agentos.workflows.requirements.nodes.generate_draft import generate_draft
    from agentos.workflows.requirements.state import create_initial_state
    
    # Verify routing doesn't block on questions
    state = {
        "error_message": "",
        "config_gates_draft": False,
    }
    
    result = route_after_generate_draft(state)
    assert result == "N3_review", "Should proceed to review without blocking"


def test_020():
    """
    Gemini answers questions | Auto | Review with question instructions |
    All questions [x] | Verdict contains resolutions
    
    Integration test verifying the review node properly detects resolved questions.
    """
    from agentos.workflows.requirements.nodes.review import (
        _check_open_questions_status,
        _verdict_has_resolved_questions,
    )
    
    draft = """### Open Questions
- [ ] First question
- [ ] Second question
- [ ] Third question
"""
    
    # Verdict with all questions resolved
    verdict = """## Open Questions Resolved
- [x] ~~First question~~ **RESOLVED: Answer 1.**
- [x] ~~Second question~~ **RESOLVED: Answer 2.**
- [x] ~~Third question~~ **RESOLVED: Answer 3.**

## Verdict
[x] **APPROVED**
"""
    
    assert _verdict_has_resolved_questions(verdict) is True
    assert _check_open_questions_status(draft, verdict) == "RESOLVED"


def test_030():
    """
    Unanswered triggers loop | Auto | Verdict approves but questions
    unchecked | Loop to N1 | Followup prompt sent
    
    Integration test verifying UNANSWERED status triggers loop back.
    """
    from agentos.workflows.requirements.nodes.review import _check_open_questions_status
    from agentos.workflows.requirements.graph import route_after_review
    
    # Draft has open questions
    draft = """### Open Questions
- [ ] Unanswered question
"""
    
    # Verdict approves but doesn't answer the question
    verdict = """## Verdict
[x] **APPROVED** - looks good overall!
"""
    
    # Verify status detection
    status = _check_open_questions_status(draft, verdict)
    assert status == "UNANSWERED", f"Expected UNANSWERED, got {status}"
    
    # Verify routing
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "UNANSWERED",
        "iteration_count": 1,
        "max_iterations": 20,
    }
    
    next_node = route_after_review(state)
    assert next_node == "N1_generate_draft", "Should loop back to drafter"


def test_040():
    """
    HUMAN REQUIRED escalates | Auto | Verdict with HUMAN REQUIRED | Goes
    to N4 | Human gate invoked
    
    Integration test verifying HUMAN REQUIRED detection and escalation.
    """
    from agentos.workflows.requirements.nodes.review import (
        _verdict_has_human_required,
        _check_open_questions_status,
    )
    from agentos.workflows.requirements.graph import route_after_review
    
    draft = """### Open Questions
- [ ] Business decision question
"""
    
    verdict = """## Open Questions Resolved
This question requires **HUMAN REQUIRED** decision - involves business policy.

## Verdict
[x] **DISCUSS**
"""
    
    # Verify detection
    assert _verdict_has_human_required(verdict) is True
    assert _check_open_questions_status(draft, verdict) == "HUMAN_REQUIRED"
    
    # Verify routing
    state = {
        "error_message": "",
        "config_gates_verdict": False,  # Gates disabled
        "lld_status": "BLOCKED",
        "open_questions_status": "HUMAN_REQUIRED",
    }
    
    next_node = route_after_review(state)
    assert next_node == "N4_human_gate_verdict", "Should escalate to human gate"


def test_050():
    """
    Max iterations respected | Auto | 20 loops without resolution |
    Terminates | Exit with current state
    
    Integration test verifying max_iterations prevents infinite loop.
    """
    from agentos.workflows.requirements.graph import route_after_review
    
    # Test at max iterations
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "UNANSWERED",
        "iteration_count": 20,
        "max_iterations": 20,
    }
    
    result = route_after_review(state)
    assert result == "N4_human_gate_verdict", "At max should go to human gate"
    
    # Test above max iterations
    state["iteration_count"] = 25
    result = route_after_review(state)
    assert result == "N4_human_gate_verdict", "Above max should go to human gate"


def test_060():
    """
    Resolved proceeds to finalize | Auto | All questions answered |
    Reaches N5 | APPROVED status
    
    Integration test verifying RESOLVED with APPROVED goes to finalize.
    """
    from agentos.workflows.requirements.graph import route_after_review
    from agentos.workflows.requirements.nodes.review import _check_open_questions_status
    
    # Verify detection of resolved questions
    draft = """### Open Questions
- [ ] Question 1
"""
    
    verdict = """## Open Questions Resolved
- [x] ~~Question 1~~ **RESOLVED: Answer provided.**

## Verdict
[x] **APPROVED**
"""
    
    status = _check_open_questions_status(draft, verdict)
    assert status == "RESOLVED"
    
    # Verify routing
    state = {
        "error_message": "",
        "config_gates_verdict": False,
        "lld_status": "APPROVED",
        "open_questions_status": "RESOLVED",
    }
    
    next_node = route_after_review(state)
    assert next_node == "N5_finalize", "Resolved + APPROVED should finalize"


def test_070():
    """
    Prompt updated | Auto | Load 0702c | Contains question instructions |
    Regex match
    
    Integration test verifying prompt file has required Issue #248 content.
    """
    possible_paths = [
        Path(__file__).parent.parent / "docs" / "skills" / "0702c-LLD-Review-Prompt.md",
        Path("docs/skills/0702c-LLD-Review-Prompt.md"),
        Path("C:/Users/mcwiz/Projects/AgentOS-248/docs/skills/0702c-LLD-Review-Prompt.md"),
    ]
    
    content = None
    for p in possible_paths:
        if p.exists():
            content = p.read_text()
            break
    
    if content is None:
        pytest.skip("Prompt file not found")
    
    # Verify required sections with regex
    assert re.search(r"Open\s+Questions\s+Protocol", content), "Should have Open Questions Protocol"
    assert re.search(r"\[x\].*~~.*~~.*\*\*RESOLVED:", content), "Should have resolution format"
    assert re.search(r"answer.*question", content, re.IGNORECASE), "Should instruct to answer questions"
    assert re.search(r"Version.*2\.5\.0", content), "Should be version 2.5.0 or later"
```