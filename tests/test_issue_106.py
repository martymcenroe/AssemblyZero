"""Test file for Issue #106.

Generated by AssemblyZero TDD Testing Workflow.
Tests for parallel workflow execution infrastructure.
"""

import os
import signal
import time
import threading
from unittest.mock import Mock, patch, MagicMock
import pytest

from assemblyzero.workflows.parallel import (
    ParallelCoordinator,
    CredentialCoordinator,
    OutputPrefixer,
    sanitize_identifier,
)
from assemblyzero.workflows.parallel.coordinator import WorkflowResult, ProgressStats


# Fixtures for mocking
@pytest.fixture
def mock_external_service():
    """Mock external service for isolation."""
    yield None


@pytest.fixture
def mock_credentials():
    """Mock credentials for testing."""
    return ["key1", "key2", "key3"]


@pytest.fixture
def credential_coordinator(mock_credentials):
    """Create a credential coordinator with mock credentials."""
    return CredentialCoordinator(mock_credentials)


# Unit Tests
# -----------

def test_010(mock_credentials):
    """
    Happy path: 3 LLDs processed in parallel | Auto | 3 mock LLDs,
    --parallel 3 | All complete, progress report shows 3/3 | Exit code 0,
    all DBs cleaned up
    """
    # TDD: Arrange
    items = ["lld-001", "lld-002", "lld-003"]
    processed = []
    
    def worker_func(item, credential):
        processed.append(item)
        time.sleep(0.01)  # Simulate some work
        
    coordinator = ParallelCoordinator(max_workers=3)
    
    # TDD: Act
    stats, results = coordinator.execute_parallel(
        items=items,
        worker_func=worker_func,
        item_id_func=lambda x: x,
        dry_run=False,
    )
    
    # TDD: Assert
    assert stats.total == 3
    assert stats.completed == 3
    assert stats.failed == 0
    assert stats.success_count == 3
    assert len(results) == 3
    assert all(r.success for r in results)
    assert set(processed) == set(items)


def test_020():
    """
    Dry run lists without executing | Auto | 5 pending items, --dry-run |
    List of 5 items printed | No subprocess spawned, no DBs created
    """
    # TDD: Arrange
    items = ["item-001", "item-002", "item-003", "item-004", "item-005"]
    executed = []
    
    def worker_func(item, credential):
        executed.append(item)
        
    coordinator = ParallelCoordinator(max_workers=3)
    
    # TDD: Act
    with patch('builtins.print') as mock_print:
        stats, results = coordinator.execute_parallel(
            items=items,
            worker_func=worker_func,
            item_id_func=lambda x: x,
            dry_run=True,
        )
    
    # TDD: Assert
    assert stats.total == 5
    assert stats.completed == 0
    assert len(results) == 0
    assert len(executed) == 0
    # Verify dry run message was printed
    assert any("Dry run mode" in str(call) for call in mock_print.call_args_list)


def test_030():
    """
    Path traversal rejected | Auto | Issue number "../etc/passwd" |
    ValueError raised | Clear error message, no file access
    """
    # TDD: Arrange
    malicious_ids = [
        "../etc/passwd",
        "../../secrets",
        "..\\windows\\system32",
        "/etc/passwd",
        "C:\\Windows\\System32",
    ]
    
    # TDD: Act & Assert
    for mal_id in malicious_ids:
        with pytest.raises(ValueError) as exc_info:
            sanitize_identifier(mal_id)
        assert "Invalid identifier" in str(exc_info.value)


def test_040(mock_credentials):
    """
    Credential exhaustion pauses workers | Auto | 5 items, 2 credentials,
    --parallel 5 | Workers pause, resume on release | Log shows
    "[COORDINATOR] Credential pool exhausted"
    """
    # TDD: Arrange
    items = [f"item-{i:03d}" for i in range(5)]
    cred_coordinator = CredentialCoordinator(["key1", "key2"])
    
    def worker_func(item, credential):
        time.sleep(0.1)  # Simulate work
        
    coordinator = ParallelCoordinator(
        max_workers=5,
        credential_coordinator=cred_coordinator,
    )
    
    # TDD: Act
    with patch('builtins.print') as mock_print:
        stats, results = coordinator.execute_parallel(
            items=items,
            worker_func=worker_func,
            item_id_func=lambda x: x,
            dry_run=False,
        )
    
    # TDD: Assert
    assert stats.total == 5
    assert stats.completed == 5
    # Check that exhaustion message was printed
    printed_output = "\n".join(str(call) for call in mock_print.call_args_list)
    assert "[COORDINATOR] Credential pool exhausted" in printed_output


def test_050():
    """
    HTTP 429 triggers backoff | Auto | AGENTOS_SIMULATE_429=true | Key
    marked rate-limited | Backoff applied, different key used or wait
    """
    # TDD: Arrange
    items = ["item-001"]
    cred_coordinator = CredentialCoordinator(["key1", "key2"])
    
    call_count = []
    
    def worker_func(item, credential):
        call_count.append(credential)
        
    coordinator = ParallelCoordinator(
        max_workers=1,
        credential_coordinator=cred_coordinator,
    )
    
    # TDD: Act
    with patch.dict(os.environ, {"AGENTOS_SIMULATE_429": "true"}):
        stats, results = coordinator.execute_parallel(
            items=items,
            worker_func=worker_func,
            item_id_func=lambda x: x,
            dry_run=False,
        )
    
    # TDD: Assert
    assert stats.total == 1
    assert stats.completed == 1
    # Should have gotten a different credential after rate limit
    assert call_count[0] is not None


def test_060():
    """
    Single workflow failure isolated | Auto | 1 invalid spec among 3 | 2
    succeed, 1 fails | Failed item in report, others complete
    """
    # TDD: Arrange
    items = ["good-001", "bad-002", "good-003"]
    
    def worker_func(item, credential):
        if "bad" in item:
            raise ValueError(f"Invalid item: {item}")
            
    coordinator = ParallelCoordinator(max_workers=3)
    
    # TDD: Act
    stats, results = coordinator.execute_parallel(
        items=items,
        worker_func=worker_func,
        item_id_func=lambda x: x,
        dry_run=False,
    )
    
    # TDD: Assert
    assert stats.total == 3
    assert stats.completed == 3
    assert stats.failed == 1
    assert stats.success_count == 2
    
    # Check specific results
    failed_results = [r for r in results if not r.success]
    assert len(failed_results) == 1
    assert "bad" in failed_results[0].item_id


def test_070():
    """
    Graceful shutdown on SIGINT | Auto | SIGINT during execution |
    Workers checkpoint and exit | All checkpoint DBs written within 5s
    """
    # TDD: Arrange
    items = [f"item-{i:03d}" for i in range(5)]
    
    def worker_func(item, credential):
        time.sleep(0.5)  # Simulate work
        
    coordinator = ParallelCoordinator(max_workers=2)
    
    # Function to send SIGINT after a delay
    def send_interrupt():
        time.sleep(0.2)
        coordinator._handle_shutdown_signal(signal.SIGINT, None)
        
    # TDD: Act
    interrupt_thread = threading.Thread(target=send_interrupt)
    interrupt_thread.start()
    
    start_time = time.time()
    stats, results = coordinator.execute_parallel(
        items=items,
        worker_func=worker_func,
        item_id_func=lambda x: x,
        dry_run=False,
    )
    duration = time.time() - start_time
    
    interrupt_thread.join()
    
    # TDD: Assert
    assert duration < 5.0, "Shutdown took too long"
    checkpoints = coordinator.get_checkpoints()
    # Some items should have been interrupted
    assert len(checkpoints) > 0


def test_080():
    """
    Output prefix prevents interleaving | Auto | 3 parallel workflows |
    All lines prefixed correctly | No partial line mixing
    """
    # TDD: Arrange
    prefixes = ["[LLD-001]", "[LLD-002]", "[LLD-003]"]
    output_lines = []
    
    def capture_output(text):
        output_lines.append(text)
        
    mock_stream = Mock()
    mock_stream.write = capture_output
    mock_stream.flush = Mock()
    
    # TDD: Act
    for prefix in prefixes:
        prefixer = OutputPrefixer(prefix, stream=mock_stream)
        prefixer.write("Line 1\n")
        prefixer.write("Line 2\n")
        prefixer.flush()
    
    # TDD: Assert
    # Check all lines have prefixes
    for line in output_lines:
        if line.strip():  # Skip empty lines
            assert any(prefix in line for prefix in prefixes)
            
    # Check no partial line mixing (each line should be complete)
    for line in output_lines:
        if "[LLD-" in line:
            # Should have complete format: "[LLD-XXX] content\n"
            assert line.count("[LLD-") == 1


def test_090():
    """
    Performance benchmark | Auto-Live | 6 items, sequential vs --parallel
    3 | Parallel < 50% sequential time | Timing comparison logged
    """
    # TDD: Arrange
    items = [f"item-{i:03d}" for i in range(6)]
    work_duration = 0.1
    
    def worker_func(item, credential):
        time.sleep(work_duration)
        
    # TDD: Act - Sequential
    sequential_start = time.time()
    for item in items:
        worker_func(item, None)
    sequential_duration = time.time() - sequential_start
    
    # TDD: Act - Parallel
    coordinator = ParallelCoordinator(max_workers=3)
    parallel_start = time.time()
    stats, results = coordinator.execute_parallel(
        items=items,
        worker_func=worker_func,
        item_id_func=lambda x: x,
        dry_run=False,
    )
    parallel_duration = time.time() - parallel_start
    
    # TDD: Assert
    assert stats.completed == 6
    assert stats.success_count == 6
    # Parallel should be significantly faster (allow some overhead)
    assert parallel_duration < sequential_duration * 0.6, \
        f"Parallel ({parallel_duration:.2f}s) not faster than sequential ({sequential_duration:.2f}s)"


def test_100():
    """
    Max parallelism enforced | Auto | Capped to 10 | Warning logged, runs
    with 10
    """
    # TDD: Arrange
    excessive_parallelism = 20
    
    # TDD: Act
    with patch('builtins.print') as mock_print:
        coordinator = ParallelCoordinator(max_workers=excessive_parallelism)
    
    # TDD: Assert
    assert coordinator.max_workers == ParallelCoordinator.MAX_PARALLELISM
    # Check warning was logged
    printed_output = "\n".join(str(call) for call in mock_print.call_args_list)
    assert "Warning" in printed_output
    assert str(ParallelCoordinator.MAX_PARALLELISM) in printed_output


def test_110():
    """
    Default parallelism applied | Auto | Uses 3 | Config shows
    max_parallelism=3
    """
    # TDD: Arrange & Act
    coordinator = ParallelCoordinator()
    
    # TDD: Assert
    assert coordinator.max_workers == ParallelCoordinator.DEFAULT_PARALLELISM
    assert coordinator.max_workers == 3


# Additional coverage tests
# -------------------------

def test_120_credential_timeout():
    """
    Test credential acquisition timeout | Coverage | All credentials busy,
    acquire with timeout | Returns None after timeout
    """
    # TDD: Arrange
    cred_coordinator = CredentialCoordinator(["key1"])
    
    # Acquire the only credential
    key = cred_coordinator.acquire(timeout=0.1)
    assert key == "key1"
    
    # TDD: Act - Try to acquire again with short timeout
    result = cred_coordinator.acquire(timeout=0.1)
    
    # TDD: Assert
    assert result is None  # Should timeout


def test_130_credential_rate_limit_release():
    """
    Test releasing credential with rate limit | Coverage | Release with
    rate_limited=True | Prints backoff message
    """
    # TDD: Arrange
    cred_coordinator = CredentialCoordinator(["key1", "key2"])
    key = cred_coordinator.acquire()
    
    # TDD: Act
    with patch('builtins.print') as mock_print:
        cred_coordinator.release(key, rate_limited=True, backoff_seconds=30.0)
    
    # TDD: Assert
    printed_output = "\n".join(str(call) for call in mock_print.call_args_list)
    assert "rate-limited" in printed_output
    assert "30" in printed_output


def test_140_sanitize_path_separators():
    """
    Test path separator rejection | Coverage | Identifiers with / or \\ |
    ValueError raised
    """
    # TDD: Arrange
    invalid_ids = [
        "path/to/something",
        "path\\to\\something",
        "item-001/subitem",
    ]
    
    # TDD: Act & Assert
    for invalid_id in invalid_ids:
        with pytest.raises(ValueError) as exc_info:
            sanitize_identifier(invalid_id)
        assert "path separators not allowed" in str(exc_info.value)


def test_150_sanitize_invalid_characters():
    """
    Test invalid character rejection | Coverage | Identifiers with special
    chars | ValueError raised
    """
    # TDD: Arrange
    invalid_ids = [
        "item@001",
        "item#001",
        "item 001",  # space
        "item$001",
    ]
    
    # TDD: Act & Assert
    for invalid_id in invalid_ids:
        with pytest.raises(ValueError) as exc_info:
            sanitize_identifier(invalid_id)
        assert "invalid characters" in str(exc_info.value)


def test_160_output_prefixer_empty_lines():
    """
    Test output prefixer with empty lines | Coverage | Write empty line |
    No prefix added to empty line
    """
    # TDD: Arrange
    output_lines = []
    
    def capture_output(text):
        output_lines.append(text)
        
    mock_stream = Mock()
    mock_stream.write = capture_output
    mock_stream.flush = Mock()
    
    prefixer = OutputPrefixer("[TEST]", stream=mock_stream)
    
    # TDD: Act
    prefixer.write("Content\n")
    prefixer.write("\n")  # Empty line
    prefixer.write("More content\n")
    
    # TDD: Assert
    assert "[TEST] Content\n" in output_lines
    assert "\n" in output_lines  # Empty line without prefix
    assert "[TEST] More content\n" in output_lines


def test_170_output_prefixer_flush_buffer():
    """
    Test output prefixer flush with buffered content | Coverage | Write
    without newline, then flush | Buffered content output with prefix
    """
    # TDD: Arrange
    output_lines = []
    
    def capture_output(text):
        output_lines.append(text)
        
    mock_stream = Mock()
    mock_stream.write = capture_output
    mock_stream.flush = Mock()
    
    prefixer = OutputPrefixer("[TEST]", stream=mock_stream)
    
    # TDD: Act
    prefixer.write("Incomplete line without newline")
    prefixer.flush()
    
    # TDD: Assert
    assert any("[TEST] Incomplete line without newline" in line for line in output_lines)


def test_180_coordinator_credential_acquisition_failure():
    """
    Test coordinator handling credential acquisition failure | Coverage |
    Credential acquire returns None | RuntimeError raised in worker
    """
    # TDD: Arrange
    items = ["item-001"]
    
    # Create mock credential coordinator that always returns None
    mock_cred_coordinator = Mock()
    mock_cred_coordinator.acquire = Mock(return_value=None)
    mock_cred_coordinator.release = Mock()
    
    def worker_func(item, credential):
        pass
        
    coordinator = ParallelCoordinator(
        max_workers=1,
        credential_coordinator=mock_cred_coordinator,
    )
    
    # TDD: Act
    stats, results = coordinator.execute_parallel(
        items=items,
        worker_func=worker_func,
        item_id_func=lambda x: x,
        dry_run=False,
    )
    
    # TDD: Assert
    assert stats.total == 1
    assert stats.completed == 1
    assert stats.failed == 1
    assert len(results) == 1
    assert not results[0].success
    assert "Failed to acquire credential" in results[0].error