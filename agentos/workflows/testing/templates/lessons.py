"""Lessons learned template for N8 documentation node.

Issue #93: N8 Documentation Node

Generates lessons learned documents from workflow execution metrics.
"""

from datetime import datetime
from pathlib import Path
from typing import Any


def generate_lessons_learned(
    issue_number: int,
    audit_dir: Path,
    state: dict[str, Any],
    repo_root: Path,
) -> Path:
    """Generate lessons learned document from workflow execution.

    Args:
        issue_number: GitHub issue number.
        audit_dir: Path to the audit directory for this issue.
        state: Current workflow state with metrics.
        repo_root: Repository root path.

    Returns:
        Path to generated lessons learned file.
    """
    # Get next file number in audit dir
    file_num = 1
    if audit_dir.exists():
        existing = list(audit_dir.glob("*-lessons-learned.md"))
        file_num = len(existing) + 1

    lessons_path = audit_dir / f"{file_num:03d}-lessons-learned.md"

    # Extract metrics from state
    iteration_count = state.get("iteration_count", 0)
    coverage_achieved = state.get("coverage_achieved", 0.0)
    coverage_target = state.get("coverage_target", 90)
    test_files = state.get("test_files", [])
    implementation_files = state.get("implementation_files", [])
    red_phase_output = state.get("red_phase_output", "")
    green_phase_output = state.get("green_phase_output", "")
    test_plan_status = state.get("test_plan_status", "UNKNOWN")
    e2e_output = state.get("e2e_output", "")
    skip_e2e = state.get("skip_e2e", False)

    # Analyze red phase for mocking patterns
    mock_patterns = _detect_mock_patterns(red_phase_output, green_phase_output)

    # Analyze coverage challenges
    coverage_challenges = _analyze_coverage_challenges(
        coverage_achieved, coverage_target, green_phase_output
    )

    # Analyze what blocked/unblocked the workflow
    blockers = _analyze_blockers(state)

    # Build lessons learned content
    content_parts = [
        f"# Lessons Learned: Issue #{issue_number}",
        "",
        f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**Workflow:** TDD Testing Workflow",
        "",
        "---",
        "",
        "## Execution Summary",
        "",
        "| Metric | Value |",
        "|--------|-------|",
        f"| Red-Green Iterations | {iteration_count} |",
        f"| Coverage Achieved | {coverage_achieved:.1f}% |",
        f"| Coverage Target | {coverage_target}% |",
        f"| Test Files | {len(test_files)} |",
        f"| Implementation Files | {len(implementation_files)} |",
        f"| Test Plan Review | {test_plan_status} |",
        f"| E2E Validation | {'Skipped' if skip_e2e else ('Passed' if 'passed' in e2e_output.lower() else 'Failed/Not Run')} |",
        "",
        "---",
        "",
        "## Coverage Challenges",
        "",
    ]

    if coverage_challenges:
        for challenge in coverage_challenges:
            content_parts.append(f"- {challenge}")
    else:
        content_parts.append("- No significant coverage challenges detected")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "## API Mocking Patterns",
        "",
    ])

    if mock_patterns:
        for pattern in mock_patterns:
            content_parts.append(f"- {pattern}")
    else:
        content_parts.append("- No specific mocking patterns detected")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "## Blockers and Resolutions",
        "",
    ])

    if blockers:
        content_parts.append("| Blocker | Resolution |")
        content_parts.append("|---------|------------|")
        for blocker, resolution in blockers:
            content_parts.append(f"| {blocker} | {resolution} |")
    else:
        content_parts.append("- No blockers encountered")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "## Recommendations",
        "",
    ])

    recommendations = _generate_recommendations(
        iteration_count, coverage_achieved, coverage_target, mock_patterns, blockers
    )
    for rec in recommendations:
        content_parts.append(f"- {rec}")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "## Test Files",
        "",
    ])
    for f in test_files:
        content_parts.append(f"- `{f}`")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "## Implementation Files",
        "",
    ])
    for f in implementation_files:
        content_parts.append(f"- `{f}`")

    content_parts.extend(["", "---", ""])

    content_parts.extend([
        "*This document was auto-generated by the TDD Testing Workflow N8 documentation node.*",
        "",
    ])

    lessons_path.write_text("\n".join(content_parts), encoding="utf-8")
    return lessons_path


def _detect_mock_patterns(red_output: str, green_output: str) -> list[str]:
    """Detect mocking patterns used in tests.

    Args:
        red_output: Red phase test output.
        green_output: Green phase test output.

    Returns:
        List of detected mock patterns.
    """
    patterns = []
    combined = red_output + green_output

    # Detect common mocking patterns
    if "mock" in combined.lower():
        patterns.append("Mock objects used (unittest.mock or similar)")

    if "@patch" in combined:
        patterns.append("Decorator-based patching (@patch)")

    if "MagicMock" in combined:
        patterns.append("MagicMock for complex object mocking")

    if "fixture" in combined.lower():
        patterns.append("Pytest fixtures for test setup")

    if "monkeypatch" in combined.lower():
        patterns.append("Pytest monkeypatch for environment/attribute patching")

    if "responses" in combined.lower() or "httpretty" in combined.lower():
        patterns.append("HTTP request mocking (responses/httpretty)")

    if "subprocess" in combined.lower() and "mock" in combined.lower():
        patterns.append("Subprocess mocking for CLI/shell commands")

    return patterns


def _analyze_coverage_challenges(
    achieved: float, target: int, test_output: str
) -> list[str]:
    """Analyze coverage challenges.

    Args:
        achieved: Achieved coverage percentage.
        target: Target coverage percentage.
        test_output: Test output string.

    Returns:
        List of coverage challenges.
    """
    challenges = []

    gap = target - achieved
    if gap > 20:
        challenges.append(f"Large coverage gap: {gap:.1f}% below target")
    elif gap > 10:
        challenges.append(f"Moderate coverage gap: {gap:.1f}% below target")
    elif gap > 0:
        challenges.append(f"Minor coverage gap: {gap:.1f}% below target")

    if "0%" in test_output and "TOTAL" in test_output:
        challenges.append("Some modules have 0% coverage")

    if "Missing" in test_output:
        challenges.append("Missing line coverage detected in report")

    return challenges


def _analyze_blockers(state: dict[str, Any]) -> list[tuple[str, str]]:
    """Analyze what blocked and unblocked the workflow.

    Args:
        state: Workflow state.

    Returns:
        List of (blocker, resolution) tuples.
    """
    blockers = []

    error_message = state.get("error_message", "")
    if error_message:
        blockers.append((f"Error: {error_message[:50]}...", "Investigate logs"))

    gemini_feedback = state.get("gemini_feedback", "")
    if gemini_feedback:
        blockers.append(("Gemini review feedback", "Addressed in revision"))

    iteration_count = state.get("iteration_count", 0)
    if iteration_count > 3:
        blockers.append((f"Multiple iterations needed ({iteration_count})", "Test/impl iteration"))

    return blockers


def _generate_recommendations(
    iterations: int,
    coverage: float,
    target: int,
    mock_patterns: list[str],
    blockers: list[tuple[str, str]],
) -> list[str]:
    """Generate recommendations based on workflow execution.

    Args:
        iterations: Number of iterations taken.
        coverage: Coverage achieved.
        target: Coverage target.
        mock_patterns: Detected mock patterns.
        blockers: Blockers encountered.

    Returns:
        List of recommendations.
    """
    recommendations = []

    if iterations > 5:
        recommendations.append(
            "High iteration count suggests complex implementation - consider breaking into smaller issues"
        )

    if coverage < target:
        recommendations.append(
            f"Coverage below target ({coverage:.1f}% < {target}%) - add tests for uncovered paths"
        )

    if not mock_patterns:
        recommendations.append(
            "No mocking detected - consider adding mocks for external dependencies"
        )

    if blockers:
        recommendations.append(
            f"Workflow had {len(blockers)} blocker(s) - review for process improvements"
        )

    if not recommendations:
        recommendations.append("Workflow completed efficiently - no major improvements needed")

    return recommendations
